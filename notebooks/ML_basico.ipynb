{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Básico — Classificação de Anomalias (Industrial Sensors)\n",
    "\n",
    "Este notebook carrega leituras de sensores, cria *features* simples e treina um classificador para identificar **anomalias** em `data/sensor_readings.csv`.\n",
    "\n",
    "**Tarefa de ML:** classificação binária (`is_anomaly` 0/1).\n",
    "**Modelo baseline:** `LogisticRegression` (rápido e interpretável).\n",
    "\n",
    "> Requisito do desafio: usar pelo menos ~500 leituras por sensor. O repositório terá uma amostra pequena; gere a versão grande depois e reenvie para a pasta `data/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se estiver no Colab, opcional: instalar dependências\n",
    "# !pip -q install pandas numpy scikit-learn matplotlib\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "BASE_DIR = Path('.')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "GRAPHS_DIR = BASE_DIR / 'graphs'\n",
    "GRAPHS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert (DATA_DIR / 'sensor_readings.csv').exists(), \"Coloque o dataset em data/sensor_readings.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "readings = pd.read_csv(DATA_DIR / 'sensor_readings.csv', parse_dates=['ts'])\n",
    "readings = readings.sort_values(['sensor_id', 'ts']).reset_index(drop=True)\n",
    "\n",
    "# Filtrar leituras válidas\n",
    "if 'status' in readings.columns:\n",
    "    readings = readings[(readings['status'] == 'OK') | (readings['status'].isna())]\n",
    "if 'quality_score' in readings.columns:\n",
    "    readings = readings[(readings['quality_score'].isna()) | (readings['quality_score'] > 0)]\n",
    "\n",
    "readings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: diferenças e janelas móveis por sensor\n",
    "def make_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = df.groupby('sensor_id', group_keys=False)\n",
    "    out = df.copy()\n",
    "    out['value_diff1'] = g['value'].diff(1)\n",
    "    out['value_diff2'] = g['value'].diff(2)\n",
    "    out['roll_mean_5'] = g['value'].rolling(5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    out['roll_std_5']  = g['value'].rolling(5, min_periods=1).std().reset_index(level=0, drop=True).fillna(0)\n",
    "    out['roll_mean_15'] = g['value'].rolling(15, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    out['roll_std_15']  = g['value'].rolling(15, min_periods=1).std().reset_index(level=0, drop=True).fillna(0)\n",
    "    out = out.dropna().reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "feat = make_features(readings)\n",
    "target_col = 'is_anomaly'\n",
    "if target_col not in feat.columns:\n",
    "    raise ValueError(\"A coluna 'is_anomaly' não está no CSV. Adicione rótulos 0/1 para treinar.\")\n",
    "\n",
    "feature_cols = ['value','value_diff1','value_diff2','roll_mean_5','roll_std_5','roll_mean_15','roll_std_15']\n",
    "X = feat[feature_cols].values\n",
    "y = feat[target_col].astype(int).values\n",
    "len(feat), feat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":_
