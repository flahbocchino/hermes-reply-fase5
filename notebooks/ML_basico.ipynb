{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Básico — Classificação de Anomalias (Industrial Sensors)\n",
    "\n",
    "Este notebook carrega leituras de sensores, cria *features* simples e treina um classificador para identificar **anomalias** em `data/sensor_readings.csv`.\n",
    "\n",
    "**Tarefa de ML:** classificação binária (`is_anomaly` 0/1).\n",
    "**Modelo baseline:** `LogisticRegression` (rápido e interpretável).\n",
    "\n",
    "> Requisito do desafio: usar pelo menos ~500 leituras por sensor. O repositório terá uma amostra pequena; gere a versão grande depois e reenvie para a pasta `data/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se estiver no Colab, opcional: instalar dependências\n",
    "# !pip -q install pandas numpy scikit-learn matplotlib\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "BASE_DIR = Path('.')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "GRAPHS_DIR = BASE_DIR / 'graphs'\n",
    "GRAPHS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert (DATA_DIR / 'sensor_readings.csv').exists(), \"Coloque o dataset em data/sensor_readings.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "readings = pd.read_csv(DATA_DIR / 'sensor_readings.csv', parse_dates=['ts'])\n",
    "readings = readings.sort_values(['sensor_id', 'ts']).reset_index(drop=True)\n",
    "\n",
    "# Filtrar leituras válidas\n",
    "if 'status' in readings.columns:\n",
    "    readings = readings[(readings['status'] == 'OK') | (readings['status'].isna())]\n",
    "if 'quality_score' in readings.columns:\n",
    "    readings = readings[(readings['quality_score'].isna()) | (readings['quality_score'] > 0)]\n",
    "\n",
    "readings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: diferenças e janelas móveis por sensor\n",
    "def make_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = df.groupby('sensor_id', group_keys=False)\n",
    "    out = df.copy()\n",
    "    out['value_diff1'] = g['value'].diff(1)\n",
    "    out['value_diff2'] = g['value'].diff(2)\n",
    "    out['roll_mean_5'] = g['value'].rolling(5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    out['roll_std_5']  = g['value'].rolling(5, min_periods=1).std().reset_index(level=0, drop=True).fillna(0)\n",
    "    out['roll_mean_15'] = g['value'].rolling(15, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    out['roll_std_15']  = g['value'].rolling(15, min_periods=1).std().reset_index(level=0, drop=True).fillna(0)\n",
    "    out = out.dropna().reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "feat = make_features(readings)\n",
    "target_col = 'is_anomaly'\n",
    "if target_col not in feat.columns:\n",
    "    raise ValueError(\"A coluna 'is_anomaly' não está no CSV. Adicione rótulos 0/1 para treinar.\")\n",
    "\n",
    "feature_cols = ['value','value_diff1','value_diff2','roll_mean_5','roll_std_5','roll_mean_15','roll_std_15']\n",
    "X = feat[feature_cols].values\n",
    "y = feat[target_col].astype(int).values\n",
    "len(feat), feat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split, escala, treino e avaliação\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc  = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_sc, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print('\\nRelatório de Classificação:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusão (matplotlib puro, sem seaborn)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "im = ax.imshow(cm, interpolation='nearest')\n",
    "ax.set_title('Matriz de Confusão')\n",
    "ax.set_xlabel('Predito')\n",
    "ax.set_ylabel('Real')\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "for (i, j), v in np.ndenumerate(cm):\n",
    "    ax.text(j, i, str(v), ha='center', va='center')\n",
    "plt.tight_layout()\n",
    "out_path = GRAPHS_DIR / 'confusion_matrix.png'\n",
    "plt.savefig(out_path, dpi=150)\n",
    "plt.show()\n",
    "print(f'Figura salva em: {out_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificativa resumida\n",
    "- **Problema:** detecção/classificação de anomalias em séries temporais de sensores.\n",
    "- **Modelo:** `LogisticRegression` como baseline pela simplicidade e velocidade; pode-se testar `RandomForest` depois.\n",
    "- **Features:** diferenças e estatísticas de janelas móveis capturam tendências e volatilidade.\n",
    "- **Métricas:** `accuracy` + relatório de classificação; se a classe 1 for rara, priorize `F1`/`Recall`.\n",
    "- **Gráfico:** matriz de confusão para visualizar acertos/erros entre classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
